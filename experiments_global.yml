defaults:
  device: "cuda"
  seed: 42
  train_size: 10000
  test_size: 1000
  targeted_data_size: 1000
  batch_size: 64
  byzantine_steps: 50
  byzantine_lr: 0.01
  aggregation_method: "mean"
  aggregator_optim: "sgd"
  aggregator_scheduler: null
  adversarial_scheduler: null #"StepLR", "CosineAnnealingLR"
  random_restarts: 1
  epochs: 50
  rounds_per_epoch: 10
  train_pct: 1.0
  source_label: 0
  target_label: 1
  dataset: "mnist"
  model_type: "LogisticRegression"
  poisoner: "4xl"
  attack_method: "global_trajectory_matching"
  # loss_type: "l2"
  budget_ratio: 1.0

experiments:
  # - num_honest_workers: 1
  #   num_byzantine_workers: 0
  #   loss_type: "l2"
  #   controlled_subset_size: 1.0

  - num_honest_workers: 0
    num_byzantine_workers: 1
    loss_type: "l2"
    controlled_subset_size: 0.25

  # - num_honest_workers: 0
  #   num_byzantine_workers: 1
  #   loss_type: "l2"
  #   controlled_subset_size: 0.25

  # - num_honest_workers: 0
  #   num_byzantine_workers: 1
  #   loss_type: "cosine_similarity"
  #   controlled_subset_size: 0.1

  # - num_honest_workers: 0
  #   num_byzantine_workers: 1
  #   loss_type: "l2"
  #   controlled_subset_size: 0.1

  # - num_honest_workers: 0
  #   num_byzantine_workers: 1
  #   loss_type: "cosine_similarity"
  #   controlled_subset_size: 0.05

  # - num_honest_workers: 0
  #   num_byzantine_workers: 1
  #   loss_type: "l2"
  #   controlled_subset_size: 0.05

